{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### PySpark Synapse Notebook to read and process the Synapse-Link Cosmos DB analytical store.\n",
        "##### Chris Joakim, 2020/12/14"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read from Cosmos DB analytical store into a Spark DataFrame and display 10 rows from the DataFrame\n",
        "# To select a preferred list of regions in a multi-region Cosmos DB account, add .option(\"spark.cosmos.preferredRegions\", \"<Region1>,<Region2>\")\n",
        "\n",
        "df = spark.read\\\n",
        "    .format(\"cosmos.olap\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDB\")\\\n",
        "    .option(\"spark.cosmos.container\", \"events\")\\\n",
        "    .load()\n",
        "\n",
        "display(df.limit(10))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the observed schema of the analytical store\n",
        "display(df.printSchema())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Produce and display a filtered DataFrame with just the pertinent IoT columns, sorted by epoch time\n",
        "from pyspark.sql import functions as f\n",
        "recent_df = df.select(\"pk\",\"line_speed\",\"temperature\",\"humidity\", \"epoch\").filter(\"epoch >= 1603986247\").sort(\"epoch\", ascending=False) \n",
        "display(recent_df.limit(10))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "sessionOptions": {
      "driverMemory": "28g",
      "driverCores": 4,
      "executorMemory": "28g",
      "executorCores": 4,
      "numExecutors": 2,
      "keepAliveTimeout": 30,
      "conf": {
        "spark.dynamicAllocation.enabled": "false",
        "spark.dynamicAllocation.minExecutors": "2",
        "spark.dynamicAllocation.maxExecutors": "2"
      }
    },
    "saveOutput": true,
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython",
      "codemirror_mode": "ipython",
      "nbconvert_exporter": "python"
    },
    "a365ComputeOptions": {
      "nodeSize": "Small",
      "auth": {
        "authResource": "https://dev.azuresynapse.net",
        "type": "AAD"
      },
      "name": "cjspark3s",
      "nodeCount": 3,
      "endpoint": "https://cjoakimiotsynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/cjspark3s",
      "automaticScaleJobs": false,
      "type": "Spark",
      "id": "/subscriptions/61761119-d249-4507-90c6-a16517e1874c/resourceGroups/cjoakim-iot-cosmosdb-synapse/providers/Microsoft.Synapse/workspaces/cjoakimiotsynapse/bigDataPools/cjspark3s",
      "sparkVersion": "2.4",
      "extraHeader": null
    },
    "microsoft": {
      "language": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}